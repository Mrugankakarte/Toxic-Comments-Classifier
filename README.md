# Toxic-Comments-Classifier

This project is based on Kaggle Competition: Toxic Comment Classification Challenge

The challenge is to build a multi-headed model that’s capable of detecting different types of of toxicity like threats, obscenity, insults, and identity-based hate better than Perspective’s current models. Comments from Wikipedia’s talk page edits was used as dataset to train models.

Link to competiton: [Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge)
